{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1472453,"sourceType":"datasetVersion","datasetId":863934}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## This notebook describes the step to manually develop an encoder model and use it to train on a dataset from kaggle for sentiment analysis.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom collections import Counter\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:38.537323Z","iopub.execute_input":"2026-02-18T14:16:38.539037Z","iopub.status.idle":"2026-02-18T14:16:38.546812Z","shell.execute_reply.started":"2026-02-18T14:16:38.538940Z","shell.execute_reply":"2026-02-18T14:16:38.545219Z"}},"outputs":[],"execution_count":445},{"cell_type":"code","source":"class EncoderBlock(nn.Module):\n    def __init__(self, emb_dim=4, nheads=1, ffn_mult=4):\n        super().__init__()\n        #layer norm before attention\n        self.ln1=nn.LayerNorm(emb_dim)\n        # multi-head attention \n        self.mha=nn.MultiheadAttention(emb_dim, nheads, batch_first=True)\n        #layer nnorm for the FF layers\n        self.ln2=nn.LayerNorm(emb_dim)\n        # FF layer\n        hidden =emb_dim * ffn_mult\n        # Two linear layers provide richer transformation than a single one\n        self.ffn=nn.Sequential(\n            nn.Linear(emb_dim, hidden),\n            nn.ReLU(),\n            nn.Linear(hidden, emb_dim)\n        )\n    def forward(self,x):\n        # self attention layer\n        x_norm=self.ln1(x)\n        attention_op,_=self.mha(x_norm, x_norm, x_norm)# representing Q, K, V vectors\n        # o/p will be added with the input to build the\n        # residual connection\n        x=x+attention_op\n\n        # FF layer\n        x_norm=self.ln2(x)\n        ff_op=self.ffn(x_norm)\n        x=x+ff_op\n        return x\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:38.573976Z","iopub.execute_input":"2026-02-18T14:16:38.575399Z","iopub.status.idle":"2026-02-18T14:16:38.585704Z","shell.execute_reply.started":"2026-02-18T14:16:38.575349Z","shell.execute_reply":"2026-02-18T14:16:38.584414Z"}},"outputs":[],"execution_count":446},{"cell_type":"code","source":"enc=EncoderBlock(emb_dim=4, nheads=1,ffn_mult=4)\nsample_ip=torch.randn(2,3,4)\nprint(sample_ip.shape)\nop=enc(sample_ip)\nprint(op.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:38.609780Z","iopub.execute_input":"2026-02-18T14:16:38.610193Z","iopub.status.idle":"2026-02-18T14:16:38.627279Z","shell.execute_reply.started":"2026-02-18T14:16:38.610161Z","shell.execute_reply":"2026-02-18T14:16:38.626180Z"}},"outputs":[{"name":"stdout","text":"torch.Size([2, 3, 4])\ntorch.Size([2, 3, 4])\n","output_type":"stream"}],"execution_count":447},{"cell_type":"code","source":"print(sample_ip, op)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:38.653822Z","iopub.execute_input":"2026-02-18T14:16:38.654163Z","iopub.status.idle":"2026-02-18T14:16:38.665706Z","shell.execute_reply.started":"2026-02-18T14:16:38.654133Z","shell.execute_reply":"2026-02-18T14:16:38.664082Z"}},"outputs":[{"name":"stdout","text":"tensor([[[ 0.0255,  1.1561, -0.3986, -0.3131],\n         [ 0.7852,  0.4384, -0.7380,  0.3271],\n         [-0.2821,  0.2723, -0.9541,  0.3321]],\n\n        [[ 0.0157, -0.4823, -0.3852, -1.4038],\n         [-1.5332,  0.3876, -0.5351,  0.5146],\n         [ 0.0317,  0.0847,  0.7276, -0.4101]]]) tensor([[[ 0.0529,  0.7691, -0.3429,  0.7733],\n         [ 0.7472, -0.0769, -0.4051,  1.2703],\n         [-0.1978, -0.1688, -0.6576,  1.3997]],\n\n        [[ 0.5068, -0.5339, -0.2660, -1.5183],\n         [-1.0082,  0.6158, -0.2217,  0.5962],\n         [ 0.7361, -0.0350,  0.9410, -0.5245]]], grad_fn=<AddBackward0>)\n","output_type":"stream"}],"execution_count":448},{"cell_type":"code","source":"# Sinusoidal positional embeddings. They can generalize well to longer sequences not \n# seen during training\nclass PositionalEmbedding(nn.Module):\n    def __init__(self, max_seq_len, emb_dimension):\n        super().__init__()\n        self.max_seq_len=max_seq_len\n        self.emb_dimension=emb_dimension\n        # create posinional embedding matrix\n        pem=torch.zeros(max_seq_len,emb_dimension)\n        position=torch.arange(0,max_seq_len).unsqueeze(1).float()\n        # 10000^{-2i/d_model}\n        even_indices=torch.arange(0, emb_dimension,2) #2i values\n        # −ln(10000)/dmodel\n        scaler_term=torch.log(torch.tensor(10000.0))/emb_dimension  \n        # 10000 −2i/dmodel\n        div_term=torch.exp(even_indices.float() * -(scaler_term))\n        # Fill even dimensions with sine values\n        pem[:,0::2]=torch.sin(position*div_term)\n        # Fill odd dimensions with cosine values\n        pem[:,1::2]=torch.cos(position*div_term)\n        # register as non trainable buffer\n        self.register_buffer('pem', pem.unsqueeze(0))\n    def forward(self, x):\n            # get the seq length\n            seq_len=x.size(1)\n            return self.pem[:,:seq_len,:]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:38.692344Z","iopub.execute_input":"2026-02-18T14:16:38.692828Z","iopub.status.idle":"2026-02-18T14:16:38.701801Z","shell.execute_reply.started":"2026-02-18T14:16:38.692784Z","shell.execute_reply":"2026-02-18T14:16:38.700614Z"}},"outputs":[],"execution_count":449},{"cell_type":"code","source":"# test\nemb_dimension=128\nmax_len=100\npos_enc=PositionalEmbedding(max_len,emb_dimension)\nbatch_size=2\nseq_len=10\ndummy_emb=torch.randn(batch_size, seq_len,emb_dimension)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:38.722620Z","iopub.execute_input":"2026-02-18T14:16:38.723039Z","iopub.status.idle":"2026-02-18T14:16:38.736898Z","shell.execute_reply.started":"2026-02-18T14:16:38.722953Z","shell.execute_reply":"2026-02-18T14:16:38.735341Z"}},"outputs":[],"execution_count":450},{"cell_type":"code","source":"print(dummy_emb.shape)\nprint(dummy_emb)\npos_enc(dummy_emb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:38.750301Z","iopub.execute_input":"2026-02-18T14:16:38.750632Z","iopub.status.idle":"2026-02-18T14:16:38.770752Z","shell.execute_reply.started":"2026-02-18T14:16:38.750604Z","shell.execute_reply":"2026-02-18T14:16:38.769534Z"}},"outputs":[{"name":"stdout","text":"torch.Size([2, 10, 128])\ntensor([[[-0.9516, -0.2559,  1.5300,  ..., -0.2252, -0.4155, -0.2399],\n         [-0.7829, -0.6417,  0.3801,  ...,  2.4412,  1.9696, -1.1654],\n         [ 0.7047,  0.2306,  0.3696,  ...,  1.1410, -0.8331,  1.0201],\n         ...,\n         [-0.9909, -0.8743,  1.3671,  ..., -1.0081,  0.8707, -0.8133],\n         [ 0.5122,  1.1875,  1.1939,  ...,  0.5370, -0.9782,  1.1669],\n         [ 1.1159, -1.7818,  0.0869,  ..., -0.8459,  0.2155,  0.8763]],\n\n        [[-0.0923, -1.0994, -0.9169,  ..., -0.8463,  0.2483,  0.4395],\n         [ 0.1922, -0.5567,  0.6774,  ...,  0.2837, -1.6245,  0.5813],\n         [ 1.4495, -0.2102, -0.0809,  ..., -0.7944, -1.6144, -0.4606],\n         ...,\n         [-0.4427, -0.3114, -0.3017,  ...,  1.3911, -0.1953,  0.0790],\n         [ 1.2849, -0.5876,  1.4305,  ...,  1.2620, -0.4614,  0.4424],\n         [ 0.0968,  0.2780,  0.4359,  ..., -2.0978, -0.5354,  0.2515]]])\n","output_type":"stream"},{"execution_count":451,"output_type":"execute_result","data":{"text/plain":"tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n           0.0000e+00,  1.0000e+00],\n         [ 8.4147e-01,  5.4030e-01,  7.6172e-01,  ...,  1.0000e+00,\n           1.1548e-04,  1.0000e+00],\n         [ 9.0930e-01, -4.1615e-01,  9.8705e-01,  ...,  1.0000e+00,\n           2.3096e-04,  1.0000e+00],\n         ...,\n         [ 6.5699e-01,  7.5390e-01, -2.1963e-01,  ...,  1.0000e+00,\n           8.0835e-04,  1.0000e+00],\n         [ 9.8936e-01, -1.4550e-01,  6.0082e-01,  ...,  1.0000e+00,\n           9.2383e-04,  1.0000e+00],\n         [ 4.1212e-01, -9.1113e-01,  9.9818e-01,  ...,  1.0000e+00,\n           1.0393e-03,  1.0000e+00]]])"},"metadata":{}}],"execution_count":451},{"cell_type":"code","source":"# used to pad the sentences with varying length to the same size.\ndef padding_mask(seq, padding_idx=0):    \n    return seq==padding_idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:38.772955Z","iopub.execute_input":"2026-02-18T14:16:38.774233Z","iopub.status.idle":"2026-02-18T14:16:38.790874Z","shell.execute_reply.started":"2026-02-18T14:16:38.774190Z","shell.execute_reply":"2026-02-18T14:16:38.789612Z"}},"outputs":[],"execution_count":452},{"cell_type":"code","source":"import os\nBASE_DIR='/kaggle/input/datasets/datatattle/covid-19-nlp-text-classification'\nTR_FILENAME='Corona_NLP_train.csv'\nTST_FILENAME='Corona_NLP_test.csv'\nTR_PATH=os.path.join(BASE_DIR, TR_FILENAME)\nTST_PATH=os.path.join(BASE_DIR, TST_FILENAME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:38.805369Z","iopub.execute_input":"2026-02-18T14:16:38.805886Z","iopub.status.idle":"2026-02-18T14:16:38.817486Z","shell.execute_reply.started":"2026-02-18T14:16:38.805854Z","shell.execute_reply":"2026-02-18T14:16:38.816363Z"}},"outputs":[],"execution_count":453},{"cell_type":"code","source":"import pandas as pd\n\ntr_df=pd.read_csv(TR_PATH, encoding='latin1')\ntr_df=tr_df[['OriginalTweet','Sentiment']][:4000]\ntr_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:38.828155Z","iopub.execute_input":"2026-02-18T14:16:38.828530Z","iopub.status.idle":"2026-02-18T14:16:39.037116Z","shell.execute_reply.started":"2026-02-18T14:16:38.828499Z","shell.execute_reply":"2026-02-18T14:16:39.035907Z"}},"outputs":[{"execution_count":454,"output_type":"execute_result","data":{"text/plain":"                                          OriginalTweet           Sentiment\n0     @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral\n1     advice Talk to your neighbours family to excha...            Positive\n2     Coronavirus Australia: Woolworths to give elde...            Positive\n3     My food stock is not the only one which is emp...            Positive\n4     Me, ready to go at supermarket during the #COV...  Extremely Negative\n...                                                 ...                 ...\n3995  Giving shout out to workers at grocery &amp; r...            Positive\n3996  @Publix Whatever happens, remain open as we al...  Extremely Positive\n3997  LOOK: Residents line up to buy basic goods at ...             Neutral\n3998  @kerrimpr Is there COVID-19 risk in fresh prod...            Positive\n3999  The economic upheaval caused by COVID 19 is ex...            Positive\n\n[4000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Me, ready to go at supermarket during the #COV...</td>\n      <td>Extremely Negative</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3995</th>\n      <td>Giving shout out to workers at grocery &amp;amp; r...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3996</th>\n      <td>@Publix Whatever happens, remain open as we al...</td>\n      <td>Extremely Positive</td>\n    </tr>\n    <tr>\n      <th>3997</th>\n      <td>LOOK: Residents line up to buy basic goods at ...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>3998</th>\n      <td>@kerrimpr Is there COVID-19 risk in fresh prod...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3999</th>\n      <td>The economic upheaval caused by COVID 19 is ex...</td>\n      <td>Positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":454},{"cell_type":"code","source":"test_df=pd.read_csv(TST_PATH, encoding='latin1')\ntest_df=test_df[['OriginalTweet','Sentiment']][:1500]\ntest_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.039600Z","iopub.execute_input":"2026-02-18T14:16:39.040331Z","iopub.status.idle":"2026-02-18T14:16:39.074855Z","shell.execute_reply.started":"2026-02-18T14:16:39.040292Z","shell.execute_reply":"2026-02-18T14:16:39.073506Z"}},"outputs":[{"execution_count":455,"output_type":"execute_result","data":{"text/plain":"                                          OriginalTweet           Sentiment\n0     TRENDING: New Yorkers encounter empty supermar...  Extremely Negative\n1     When I couldn't find hand sanitizer at Fred Me...            Positive\n2     Find out how you can protect yourself and love...  Extremely Positive\n3     #Panic buying hits #NewYork City as anxious sh...            Negative\n4     #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral\n...                                                 ...                 ...\n1495  Travelzoo offering holidays for Â£33? sad thin...            Negative\n1496  Yes, I blame Communist China &amp; their Wuhan...            Positive\n1497  How many Retail store CEOs can I get to compli...  Extremely Positive\n1498  Elbow Bump is the new way to streamline your d...             Neutral\n1499  I'm totally giving all my love to a) 811 opera...  Extremely Positive\n\n[1500 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n      <td>Extremely Negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Find out how you can protect yourself and love...</td>\n      <td>Extremely Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1495</th>\n      <td>Travelzoo offering holidays for Â£33? sad thin...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>1496</th>\n      <td>Yes, I blame Communist China &amp;amp; their Wuhan...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>1497</th>\n      <td>How many Retail store CEOs can I get to compli...</td>\n      <td>Extremely Positive</td>\n    </tr>\n    <tr>\n      <th>1498</th>\n      <td>Elbow Bump is the new way to streamline your d...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1499</th>\n      <td>I'm totally giving all my love to a) 811 opera...</td>\n      <td>Extremely Positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>1500 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":455},{"cell_type":"code","source":"tr_df.Sentiment.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:37:14.232941Z","iopub.execute_input":"2026-02-18T14:37:14.233502Z","iopub.status.idle":"2026-02-18T14:37:14.249035Z","shell.execute_reply.started":"2026-02-18T14:37:14.233467Z","shell.execute_reply":"2026-02-18T14:37:14.247847Z"}},"outputs":[{"execution_count":474,"output_type":"execute_result","data":{"text/plain":"Sentiment\nPositive              1092\nNegative              1008\nNeutral                696\nExtremely Negative     618\nExtremely Positive     586\nName: count, dtype: int64"},"metadata":{}}],"execution_count":474},{"cell_type":"markdown","source":"## 5 classes of Sentiments","metadata":{}},{"cell_type":"code","source":"def check_data(ds):\n    # length of dataset\n    print(len(ds))\n    # number of classes\n    print(ds.Sentiment.unique())\n    inp=ds.OriginalTweet\n    ds['Tweet_length']=ds.OriginalTweet.apply(lambda x: len(x.split()))\n    print(ds['Tweet_length'].describe())\n   \n    \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.076266Z","iopub.execute_input":"2026-02-18T14:16:39.076544Z","iopub.status.idle":"2026-02-18T14:16:39.084131Z","shell.execute_reply.started":"2026-02-18T14:16:39.076507Z","shell.execute_reply":"2026-02-18T14:16:39.082767Z"}},"outputs":[],"execution_count":456},{"cell_type":"code","source":"check_data(tr_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.086719Z","iopub.execute_input":"2026-02-18T14:16:39.087203Z","iopub.status.idle":"2026-02-18T14:16:39.128161Z","shell.execute_reply.started":"2026-02-18T14:16:39.087172Z","shell.execute_reply":"2026-02-18T14:16:39.126878Z"}},"outputs":[{"name":"stdout","text":"4000\n['Neutral' 'Positive' 'Extremely Negative' 'Negative' 'Extremely Positive']\ncount    4000.000000\nmean       32.029000\nstd        11.661182\nmin         4.000000\n25%        23.000000\n50%        34.000000\n75%        41.000000\nmax        61.000000\nName: Tweet_length, dtype: float64\n","output_type":"stream"}],"execution_count":457},{"cell_type":"code","source":"check_data(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.129540Z","iopub.execute_input":"2026-02-18T14:16:39.129939Z","iopub.status.idle":"2026-02-18T14:16:39.153563Z","shell.execute_reply.started":"2026-02-18T14:16:39.129898Z","shell.execute_reply":"2026-02-18T14:16:39.152365Z"}},"outputs":[{"name":"stdout","text":"1500\n['Extremely Negative' 'Positive' 'Extremely Positive' 'Negative' 'Neutral']\ncount    1500.000000\nmean       32.630667\nstd        11.678407\nmin         6.000000\n25%        24.000000\n50%        34.000000\n75%        42.000000\nmax        62.000000\nName: Tweet_length, dtype: float64\n","output_type":"stream"}],"execution_count":458},{"cell_type":"code","source":"tr_df.Sentiment.unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.155108Z","iopub.execute_input":"2026-02-18T14:16:39.155636Z","iopub.status.idle":"2026-02-18T14:16:39.180052Z","shell.execute_reply.started":"2026-02-18T14:16:39.155596Z","shell.execute_reply":"2026-02-18T14:16:39.178597Z"}},"outputs":[{"execution_count":459,"output_type":"execute_result","data":{"text/plain":"array(['Neutral', 'Positive', 'Extremely Negative', 'Negative',\n       'Extremely Positive'], dtype=object)"},"metadata":{}}],"execution_count":459},{"cell_type":"code","source":"import re\nfrom collections import Counter\n\nclass CovidTweetTokenizer:\n    def __init__(self,vocabulary_size=5000):\n        self.counter=Counter()\n        # define the 4 reserved tokens\n        self.word2idx={'<PAD>':0,'<SOS>':1,'<EOS>':2,'<UNK>':3 }\n        self.idx2word={0:'<PAD>',1:'<SOS>',2:'<EOS>',3:'<UNK>'}\n        self.vocabulary_size=vocabulary_size\n    def tokenize(self,text):\n        #print(text)\n        text=text.lower()\n        text=re.sub(r'^a-z\\s', '', text)\n        words=text.split()\n        return words\n\n    def build_vocab(self,texts, min_freq=2):\n        for text in texts:\n            words=self.tokenize(text)\n            self.counter.update(words)\n        # find the most common words in the corpus\n        common_words=self.counter.most_common(self.vocabulary_size-4)\n        #print(common_words)\n        idx=4 # starting word indexing after the reserved indices\n        for word, freq in common_words:\n            if freq>min_freq:\n                self.word2idx[word]=idx\n                self.idx2word[idx]=word\n                idx+=1\n\n    def encode(self,text, max_length=128):\n         tokens=self.tokenize(text)\n         #print(tokens)\n         numerical_ids=[1] # sequence start token\n         for token in tokens:\n             if token in self.word2idx:\n                 numerical_ids.append(self.word2idx[token])\n             else:\n                 # append unknown token\n                 numerical_ids.append(3)\n         # end the sequence\n         numerical_ids.append(2)\n         while len(numerical_ids) < max_length:\n                numerical_ids.append(0)\n         return numerical_ids[:max_length]\n     \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.182004Z","iopub.execute_input":"2026-02-18T14:16:39.182469Z","iopub.status.idle":"2026-02-18T14:16:39.205607Z","shell.execute_reply.started":"2026-02-18T14:16:39.182429Z","shell.execute_reply":"2026-02-18T14:16:39.204361Z"}},"outputs":[],"execution_count":460},{"cell_type":"code","source":"\ntk=CovidTweetTokenizer()\ntk.build_vocab(tr_df.OriginalTweet)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.207106Z","iopub.execute_input":"2026-02-18T14:16:39.207940Z","iopub.status.idle":"2026-02-18T14:16:39.301376Z","shell.execute_reply.started":"2026-02-18T14:16:39.207883Z","shell.execute_reply":"2026-02-18T14:16:39.300031Z"}},"outputs":[],"execution_count":461},{"cell_type":"code","source":"# test\ntk.encode(\"This is hopeless\",20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.302605Z","iopub.execute_input":"2026-02-18T14:16:39.303216Z","iopub.status.idle":"2026-02-18T14:16:39.311397Z","shell.execute_reply.started":"2026-02-18T14:16:39.303179Z","shell.execute_reply":"2026-02-18T14:16:39.309917Z"}},"outputs":[{"execution_count":462,"output_type":"execute_result","data":{"text/plain":"[1, 21, 12, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"},"metadata":{}}],"execution_count":462},{"cell_type":"code","source":"class CovidTweetDataset(Dataset):\n    def __init__(self, tweets, labels, tokenizer, max_length):\n        super().__init__()\n        self.tokenizer=tokenizer\n        self.inputs=[]\n        self.labels=[]\n        self.max_length=max_length\n\n        # get the numerical ids for every tweet\n        for tweet, label in zip(tweets, labels):            \n            encoded_tweet=self.tokenizer.encode(tweet,self.max_length)\n            self.inputs.append(encoded_tweet)\n            self.labels.append(label)\n        self.inputs=torch.tensor(self.inputs, dtype=torch.long)\n        self.labels=torch.tensor(self.labels, dtype=torch.long)\n        \n        \n    def __len__(self):\n        return len(self.inputs)\n    def __getitem__(self, idx):\n        return self.inputs[idx], self.labels[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.314487Z","iopub.execute_input":"2026-02-18T14:16:39.314890Z","iopub.status.idle":"2026-02-18T14:16:39.338393Z","shell.execute_reply.started":"2026-02-18T14:16:39.314859Z","shell.execute_reply":"2026-02-18T14:16:39.337220Z"}},"outputs":[],"execution_count":463},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ntr_df['encoded_labels']=le.fit_transform(tr_df['Sentiment'])\ntest_df['encoded_labels']=le.transform(test_df['Sentiment'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.339880Z","iopub.execute_input":"2026-02-18T14:16:39.340251Z","iopub.status.idle":"2026-02-18T14:16:39.373031Z","shell.execute_reply.started":"2026-02-18T14:16:39.340220Z","shell.execute_reply":"2026-02-18T14:16:39.371804Z"}},"outputs":[],"execution_count":464},{"cell_type":"code","source":"train_tweets=tr_df.OriginalTweet\ntrain_labels=tr_df.encoded_labels\n\ntest_tweets=test_df.OriginalTweet\ntest_label=test_df.encoded_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.374706Z","iopub.execute_input":"2026-02-18T14:16:39.375119Z","iopub.status.idle":"2026-02-18T14:16:39.399549Z","shell.execute_reply.started":"2026-02-18T14:16:39.375075Z","shell.execute_reply":"2026-02-18T14:16:39.397900Z"}},"outputs":[],"execution_count":465},{"cell_type":"code","source":"train_ds=CovidTweetDataset(train_tweets,train_labels, tk, max_length=128)\ntest_ds=CovidTweetDataset(test_tweets,test_label, tk, max_length=128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.400859Z","iopub.execute_input":"2026-02-18T14:16:39.401372Z","iopub.status.idle":"2026-02-18T14:16:39.582598Z","shell.execute_reply.started":"2026-02-18T14:16:39.401342Z","shell.execute_reply":"2026-02-18T14:16:39.581169Z"}},"outputs":[],"execution_count":466},{"cell_type":"code","source":"batch=next(iter(train_ds))\nbatch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.583948Z","iopub.execute_input":"2026-02-18T14:16:39.584374Z","iopub.status.idle":"2026-02-18T14:16:39.594480Z","shell.execute_reply.started":"2026-02-18T14:16:39.584336Z","shell.execute_reply":"2026-02-18T14:16:39.593065Z"}},"outputs":[{"execution_count":467,"output_type":"execute_result","data":{"text/plain":"(tensor([1, 3, 3, 3, 3, 6, 3, 6, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]),\n tensor(3))"},"metadata":{}}],"execution_count":467},{"cell_type":"code","source":"class CovidTweetEncoderModel(nn.Module):\n    def __init__(self, vocab_size, embedding_dimension=128, n_layers=5, max_seq_len=256, dropout=.01):\n        super().__init__()\n        self.embedding_dimension=embedding_dimension\n        self.embedding=nn.Embedding(vocab_size,embedding_dimension,0 )\n        self.POE=PositionalEmbedding(max_seq_len,embedding_dimension)\n        self.dropout=nn.Dropout(dropout)\n        self.encoder_layers=nn.ModuleList([EncoderBlock(embedding_dimension, nheads=4,ffn_mult=4 ) for _ in range(n_layers)])\n        self.classifier=nn.Linear(embedding_dimension, 5)\n    def forward(self,x):\n        x=self.embedding(x)\n        x_poe=self.POE(x)\n        x=x+x_poe\n        x=self.dropout(x)\n        for enc in self.encoder_layers:\n            x=enc(x)\n        x=x.mean(dim=1)\n        output=self.classifier(x)\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.596056Z","iopub.execute_input":"2026-02-18T14:16:39.596475Z","iopub.status.idle":"2026-02-18T14:16:39.616864Z","shell.execute_reply.started":"2026-02-18T14:16:39.596433Z","shell.execute_reply":"2026-02-18T14:16:39.615547Z"}},"outputs":[],"execution_count":468},{"cell_type":"code","source":"vocab_size=len(tk.word2idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.618269Z","iopub.execute_input":"2026-02-18T14:16:39.618715Z","iopub.status.idle":"2026-02-18T14:16:39.654533Z","shell.execute_reply.started":"2026-02-18T14:16:39.618673Z","shell.execute_reply":"2026-02-18T14:16:39.653071Z"}},"outputs":[],"execution_count":469},{"cell_type":"code","source":"model=CovidTweetEncoderModel(vocab_size,128,5)\nloss_fn=nn.CrossEntropyLoss()\noptimizer=optim.Adam(model.parameters(), lr=.01)\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.656125Z","iopub.execute_input":"2026-02-18T14:16:39.656687Z","iopub.status.idle":"2026-02-18T14:16:39.697246Z","shell.execute_reply.started":"2026-02-18T14:16:39.656646Z","shell.execute_reply":"2026-02-18T14:16:39.696158Z"}},"outputs":[],"execution_count":470},{"cell_type":"code","source":"train_dl=DataLoader(train_ds, batch_size=32, shuffle=True)\ntest_dl=DataLoader(test_ds, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.698630Z","iopub.execute_input":"2026-02-18T14:16:39.699091Z","iopub.status.idle":"2026-02-18T14:16:39.705552Z","shell.execute_reply.started":"2026-02-18T14:16:39.699047Z","shell.execute_reply":"2026-02-18T14:16:39.704434Z"}},"outputs":[],"execution_count":471},{"cell_type":"code","source":"def train_model(model,train_ds, test_ds,loss_fn,optimizer,epochs=20,device=None):\n    if device is None:\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model=model.to(device)\n    history={\"train_acc\":[], \"test_acc\":[],\"train_loss\":[],\"test_loss\":[]}\n    \n    for epoch in range(epochs):\n        print(f\"epoch: {epoch+1}\")\n        model.train()\n        tr_loss=0\n        total_train_size=0\n        tr_correct=0\n        for inputs, labels in train_ds:\n            optimizer.zero_grad()\n            inputs=inputs.to(device)\n            labels=labels.to(device)\n    \n            outputs=model(inputs)\n            loss=loss_fn(outputs, labels)\n            # print(\"loss.requires_grad:\", loss.requires_grad)\n            # print(\"loss.grad_fn:\", getattr(loss, \"grad_fn\", None))\n            # print(\"any param requires_grad?:\", any(p.requires_grad for p in model.parameters()))\n            # print(\"model training mode:\", model.training)\n            \n            loss.backward()\n            optimizer.step()\n    \n            _, predicted=torch.max(outputs,1)\n            total_train_size+=len(labels)\n            tr_correct+=(predicted==labels).sum().item()\n            tr_loss+=loss.item()* len(labels)\n    \n            train_acc=100* tr_correct/total_train_size\n            tr_avg_loss=tr_loss/total_train_size\n        print(f\"train acc: {train_acc} train loss: {tr_avg_loss}\")\n            \n        model.eval()\n        test_loss=0\n        total_test_size=0\n        test_correct=0\n        with torch.no_grad():\n            for inputs, labels in test_dl:\n                inputs=inputs.to(device)\n                labels=labels.to(device)\n    \n                outputs=model(inputs)\n                loss=loss_fn(outputs, labels)          \n                \n                _, predicted=torch.max(outputs,1)\n                total_test_size+=len(labels)\n                test_correct+=(predicted==labels).sum().item()\n                test_loss+=loss.item()* len(labels)\n        \n                test_acc=100* test_correct/total_test_size\n                test_avg_loss=test_loss/total_test_size\n            print(f\"test acc: {test_acc} test loss: {test_avg_loss}\")\n            \n        history['train_acc'].append(train_acc)\n        history['test_acc'].append(test_acc)\n        history['train_loss'].append(tr_avg_loss)\n        history['test_loss'].append(test_avg_loss)\n    return history\n        \n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.706786Z","iopub.execute_input":"2026-02-18T14:16:39.707112Z","iopub.status.idle":"2026-02-18T14:16:39.730669Z","shell.execute_reply.started":"2026-02-18T14:16:39.707085Z","shell.execute_reply":"2026-02-18T14:16:39.729510Z"}},"outputs":[],"execution_count":472},{"cell_type":"code","source":"history=train_model(model,train_dl, test_dl,loss_fn,optimizer,epochs=10,device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T14:16:39.732442Z","iopub.execute_input":"2026-02-18T14:16:39.733373Z","iopub.status.idle":"2026-02-18T14:37:05.498363Z","shell.execute_reply.started":"2026-02-18T14:16:39.733267Z","shell.execute_reply":"2026-02-18T14:37:05.497116Z"}},"outputs":[{"name":"stdout","text":"epoch: 1\ntrain acc: 23.975 train loss: 2.804992370605469\ntest acc: 23.466666666666665 test loss: 1.576015175819397\nepoch: 2\ntrain acc: 30.05 train loss: 1.5311879196166993\ntest acc: 27.4 test loss: 1.6575156456629436\nepoch: 3\ntrain acc: 34.6 train loss: 1.4766562576293945\ntest acc: 32.13333333333333 test loss: 1.5302965078353883\nepoch: 4\ntrain acc: 36.5 train loss: 1.461296238899231\ntest acc: 31.4 test loss: 1.5350473219553629\nepoch: 5\ntrain acc: 41.025 train loss: 1.3653128747940064\ntest acc: 31.733333333333334 test loss: 1.5539536774953207\nepoch: 6\ntrain acc: 45.475 train loss: 1.2980395460128784\ntest acc: 36.266666666666666 test loss: 1.4837761917114258\nepoch: 7\ntrain acc: 48.6 train loss: 1.2083226451873779\ntest acc: 37.666666666666664 test loss: 1.5403889430363973\nepoch: 8\ntrain acc: 46.65 train loss: 1.271181414604187\ntest acc: 30.733333333333334 test loss: 1.640172616004944\nepoch: 9\ntrain acc: 37.425 train loss: 12.440426169395447\ntest acc: 22.6 test loss: 198.07689298502603\nepoch: 10\ntrain acc: 24.45 train loss: 57.195771238327026\ntest acc: 26.533333333333335 test loss: 3.5076154950459797\n","output_type":"stream"}],"execution_count":473},{"cell_type":"markdown","source":"## Best Model Accuracy: 37.6%\n\n## Future Improvements\n\n     More epochs\n    \n     Learning rate tuning\n    \n     Class imbalance handling\n    \n     Pretrained encoder instead of training from scratch","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}